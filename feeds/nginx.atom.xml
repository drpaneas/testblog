<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Linux = 'ed'</title><link href="http://drpaneas.github.io/testblog/" rel="alternate"></link><link href="http://drpaneas.github.io/testblog/feeds/nginx.atom.xml" rel="self"></link><id>http://drpaneas.github.io/testblog/</id><updated>2015-02-12T21:34:00+02:00</updated><entry><title>paok</title><link href="http://drpaneas.github.io/testblog/paok" rel="alternate"></link><updated>2015-02-12T21:34:00+02:00</updated><author><name>Πανος Γεωργιαδης</name></author><id>tag:drpaneas.github.io,2015-02-12:testblog/paok</id><summary type="html">&lt;p&gt;Σε αυτό το άρθρο θα μιλήσουμε για βασικές ρυθμήσεις που πρέπει να κάνουμε
στον Nginx. Οι ρυθμήσεις αυτές έχουν περισσότερο την έννοια του 
optimization, παρά του configuration, καθώς ο Nginx έρχεται &lt;em&gt;pretty much&lt;/em&gt;
configured, οπότε εδώ θα μιλήσουμε τις &lt;strong&gt;βέλτιστες ρυθμήσεις&lt;/strong&gt;. Για να κάνω μία
εισαγωγή, θα μιλήσουμε για πράγματα όπως: &lt;em&gt;πόση μνήμη έχουμε διαθέσιμη&lt;/em&gt;,
&lt;em&gt;πόσους πυρήνες (cpu) θα διαθέσουμε&lt;/em&gt;, και πώς αυτά θα επιδράσουν 
στον συνολικό αριθμό των &lt;em&gt;processes&lt;/em&gt;, &lt;em&gt;threads&lt;/em&gt;, κ.α. πραγμάτων που σχετίζονται
με τους πόρους και την λειτουργία του Nginx &lt;strong&gt;στο σύστημά μας&lt;/strong&gt;. Τονίζω το
&amp;#8220;&lt;em&gt;σύστημά μας&lt;/em&gt;&amp;#8221; γιατί ο σκοπός μου δεν είναι να σας δώσω έτοιμο το 
&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt; αλλά να σας δείξω ποιες ρυθμήσεις είναι &lt;em&gt;common use&lt;/em&gt;
και ποιες χρειάζονται λίγο &lt;em&gt;tweaking&lt;/em&gt; από την πλευρά&amp;nbsp;σας. &lt;/p&gt;
&lt;p&gt;Πάμε λοιπόν&amp;nbsp;&amp;#8230;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;vim /etc/nginx/nginx.conf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Το αρχείο με το οποίο θα ασχοληθούμε, είναι το &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;
το οποίο αποτελεί το βασικό αρχείο ρυθμήσεων του Nginx. Είναι το Νο1
αρχείο στο οποίο κοιτάει ο Nginx να βρει πληροφορίες. Μόλις το ανοίξετε,
θα δείτε ένα χάος από επιλογές και μεταβλητές οι οποίες άλλες είναι ήδη
&lt;em&gt;defined&lt;/em&gt; κι άλλες είναι απλά μαρκαρισμένες ως &lt;code&gt;#comment&lt;/code&gt;. Μην σας πιάνει
πανικός, πάμε να τις&amp;nbsp;δούμε:&lt;/p&gt;
&lt;h3 id="worker-processes"&gt;Worker&amp;nbsp;Processes&lt;/h3&gt;
&lt;p&gt;Η μεταβλητή &lt;code&gt;worker_processes&lt;/code&gt; μαζί με την &lt;code&gt;worker_connections&lt;/code&gt; που θα δούμε
στην συνέχεια, αποτελούν στην ουσία το &lt;em&gt;backbone&lt;/em&gt; του Nginx. Ξεκινόντας
με την πρώτη, αυτό που κάνει είναι να λέει στον server (ή τον virtual server)
πόσους workers να διαθέσει για ένα connection. Μόλις ολοκληρωθεί το
&lt;em&gt;πάρε-δώσε&lt;/em&gt; τον μηνυμάτων και οριστικοποιηθούν έννοιες όπως &lt;em&gt;dest &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/em&gt;,
&lt;em&gt;source &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/em&gt;, &lt;em&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; Port&lt;/em&gt;, &lt;em&gt;&lt;span class="caps"&gt;UDP&lt;/span&gt; Port&lt;/em&gt;, τότε ο Nginx κάνει spawn μία στρατιά
από &lt;em&gt;workers&lt;/em&gt; οι οποίοι είναι υπεύθυνοι για κατάσταση του εκάστωτε &lt;em&gt;connection&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;παράδειγμα&lt;/em&gt;: Όταν συνδέεστε στο &lt;code&gt;localhost:80&lt;/code&gt;, ο Nginx θα ψάξει να δει τι τιμή
έχει η μεταβλητή &lt;code&gt;worker_processes&lt;/code&gt; και ανάλογα θα πράξει. Από default λοιπόν
αυτή η λειτουργία αξιοποιείται στην &lt;code&gt;TCP 80&lt;/code&gt; για &lt;code&gt;http&lt;/code&gt; protocol και στην
&lt;code&gt;TCP 443&lt;/code&gt; για &lt;code&gt;ssl&lt;/code&gt; (μην μπερδεύεστε, το &lt;code&gt;https&lt;/code&gt; εννοώ). Για οποιοδήποτε άλλο
&lt;code&gt;socket&lt;/code&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, θα πρέπει να το ρυθμήσουμε διαφορετικά ή να αγοράσουμε το
εμπορικό μέρος του Nginx. Δεν είμα όμως σίγουρος, οπότε λέω να μην σας μπλέξω
με αυτό. Άλλωστε δεν νομίζω να το χρειάζεστε, εκτός κι αν έχετε κάποιο
αρκετά σύνθετο configuration, όπως για παράδειγμα πολλά &lt;code&gt;ethX&lt;/code&gt; interfaces
ή πολλά &lt;em&gt;&lt;span class="caps"&gt;VM&lt;/span&gt;&lt;/em&gt;s σε &lt;code&gt;bridge mode&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;H formula που χρησιμοποιείται ευρέως στο Internet&amp;nbsp;λέει:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1 worker για κάθε core&amp;nbsp;processor&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Προφανώς αυτό δεν είναι πανάκεια, δηλαδή μπορεί κάποιος να πει:
&amp;#8220;&lt;em&gt;Και γιατί ρε φίλε να μην βάλω 2 workers για κάθε core; Θα πάθει κάτι;
Θα χαλάσει;&lt;/em&gt;&amp;#8220;. Η απάντηση είναι, χμ, οκ δεν θα πάθει κάτι αλλά είναι
&lt;em&gt;bad practice&lt;/em&gt;, και ως &lt;em&gt;side effect&lt;/em&gt; μπορεί να έχει κάποια connections
να παραμένουν &lt;em&gt;idle&lt;/em&gt; για αρκετό διάστημα, στα οποία όμως να σπαταλούνται
workers, άρα επεξεργαστική ισχύ. Κακή διαχείριση πόρων λοιπόν &amp;#8212; είναι κάτι
που θέλουμε να αποφύγουμε, ειδικά στην περίπτωση μου που έχω έναν μικρό
Atom Processor. Στην δική μου περίπτωση λοιπόν, γνωρίζω ότι έχω έναν
&lt;em&gt;Intel(R) Atom(&lt;span class="caps"&gt;TM&lt;/span&gt;) &lt;span class="caps"&gt;CPU&lt;/span&gt; N2800 @ 1.86GHz&lt;/em&gt;, o οποίος σύμφωνα με τα 
&lt;a href="http://ark.intel.com/products/58917/Intel-Atom-Processor-N2800-1M-Cache-1_86-GHz"&gt;specs&lt;/a&gt; είναι dual core με hyperthreading. Αυτό σημαίνει ότι έχω 4 threads.
Άρα, σύμφωνα με την παραπάνω formula, θα δώσω 1 worker για κάθε thread,&amp;nbsp;συνεπώς:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;worker_processes  4;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Στην δική σας περίπτωση, αν δεν γνωρίζετε τι επεξεργαστή τρέχετε στον server,
ή το &lt;span class="caps"&gt;VPS&lt;/span&gt;, μπορείτε απλά να ρίξετε μια ματιά στο &lt;code&gt;/proc/cpuinfo/&lt;/code&gt;. Για κάποιον
ηλίθιο λόγο, έχουν μπερδέψει την έννοια του &lt;code&gt;processor&lt;/code&gt; με του &lt;code&gt;thread&lt;/code&gt;, οπότε
αρκεί να μετρήσετε πόσα &lt;em&gt;instances&lt;/em&gt; του &lt;code&gt;processor&lt;/code&gt; σας εμφανίζει. Για να μάθετε
να σκέφτεστε με εντολές bash, αυτό προϋποθέτει ένα &lt;code&gt;cat&lt;/code&gt; του αρχείου, στην 
συνέχεια ένα &lt;code&gt;grep&lt;/code&gt; του &lt;em&gt;string&lt;/em&gt; &lt;code&gt;processor&lt;/code&gt; μέσω ενός &lt;code&gt;|&lt;/code&gt;, το οποίο στην περίπτωση μου, θα&amp;nbsp;δώσε:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ns348481:~ # cat /proc/cpuinfo | grep &amp;quot;processor&amp;quot;
processor   : 0
processor   : 1
processor   : 2
processor   : 3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Οπότε, είτε μετράω με το μάτι, και βλέπω 4 processors (n+1) γιατί
ξεκινάει από τον &amp;#8220;μηδέν&amp;#8221;, ή απλά ξανά κάνω &lt;code&gt;pipe&lt;/code&gt; και περνάω τα instances
από έναν &lt;em&gt;μετρητή ανα γραμμή&lt;/em&gt;, δηλαδή &lt;code&gt;wc -l&lt;/code&gt;, δηλαδή κάπως&amp;nbsp;έτσι:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat /proc/cpuinfo | grep &amp;quot;processor&amp;quot; | wc -l
4
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Αν κάνω το λάθος, το παίξω &lt;em&gt;άπλας&lt;/em&gt;, και δώσω μεγαλύτερο νούμερο, τότε
για τον δικό μου server σημαίνει ότι δεσμεύω περισσότερους υπολογιστικούς
πόρους από όσους πραγματικά έχω. Τι θα γίνει λοιπόν στην περίπτωση όπου υπάρχει
όντως μεγάλο &lt;em&gt;load&lt;/em&gt; και θα χρειαστούν αυτοί οι παραπάνω πόροι (τους οποίους
δήλωσα εσφαλμένα ότι έχω;) ; Πρόβλημα! Για αυτό λοιπόν, σαν καλός μηχανικός
θα δώσω τον σωστό αριθμό, και θα αφήσω τα &lt;em&gt;μεγάλα λόγια&lt;/em&gt; για τους πολιτικούς.
Computers don&amp;#8217;t&amp;nbsp;lie.&lt;/p&gt;
&lt;h3 id="worker-connections"&gt;Worker&amp;nbsp;Connections&lt;/h3&gt;
&lt;p&gt;Η δεύτερη αλλά εξίσου σημαντική μεταβλητή, είναι η &lt;code&gt;worker_connections&lt;/code&gt;
η οποία βρίσκεται μέσα στο &lt;code&gt;events {}&lt;/code&gt; structure. Το νούμερο που θα βάλουμε εδώ
συμβολίζει το αριθμό των ταυτόχρονων connections. Με άλλα λόγια, είναι το
πόσοι users μπορούν να συνδεθούν ταυτόχρονα, στον server. Αν και αυτό δεν
είναι απολύτως σωστό, καθώς αν και συνήθως στην θεωρία ο browser ανοίγει
ένα connection, στην πράξη αυτο φαίνεται να είναι 3 ή τουλάχιστον παραπάνω
από 1. By default, ο Nginx έχει ορίσει την τιμή στα &lt;code&gt;768&lt;/code&gt; connections, αλλά 
εμείς θα θέσουμε την βέλτιστη τιμή για το σύστημά σας, την οποία θα μας δώσει
η εντολή &lt;code&gt;ulimit&lt;/code&gt;. Αρκετές φορές χρησιμοποιώ αυτή την εντολή, ειδικά όταν
τρέχω κάποιον &lt;em&gt;bug reproducer&lt;/em&gt; όπου γνωρίζω εκ των πρωτέρων ότι θα έρθω
αντιμέτωπος με κάποιο &lt;code&gt;segmentation fault&lt;/code&gt;. Για να μπορέσω να κάνω debugging
με το &lt;code&gt;gdb&lt;/code&gt;, θα πρέπει να ορίσω τον αριρθμό τον maximum resources που μπορώ να
δεσμεύσω στο σύστημα (και εδώ έρχεται η &lt;code&gt;ulimit&lt;/code&gt;). Σε διαφορετική, αν το σύστημα
αρχίζει να τρέχει υπερβολικά πολλές processes ή να καταναλώνει υπερβολική μνήμη
τότε είναι θέμα χρόνου μέχρι να γίνει το όλο πράγμα &lt;em&gt;unresponsive&lt;/em&gt;. 
Για όσους δεν πιστεύουν ότι μπορεί να κρασάρει το Linux, be my guest και 
τρέξτε την ακόλουθη εντολή &lt;code&gt;:(){ :|:&amp;amp; };:&lt;/code&gt; η οποία είναι κλασσικό &lt;code&gt;fork bomb&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Λέγοντας όλα αυτά, είναι εμφανές ότι ο Nginx θέλει να αποφύγει παρόμοια προβλήματα τα οποία θα οφείλονται σε μαζική κίνηση από έναν ή περισσότερους users.
Βάζοντας μια μικρή τιμή, τότε περιορίζουμε την επισκεψημότητά μας, ενώ
βάζοντας υψηλή τιμή υπερεκτιμάμε τις δυνατότητες του μηχανήματός μας. Η πιο
σωστή επιλογή λοιπόν είναι να βάλουμε ακριβώς το &lt;em&gt;sweet spot&lt;/em&gt;, το οποίο θα μας
το δώσει η εκτέλεση της εντολής &lt;code&gt;ulimit -n&lt;/code&gt;. Στην δική μου περίπτωση, το
&lt;em&gt;output&lt;/em&gt; της εντολής είναι &lt;code&gt;1024&lt;/code&gt;, οπότε πάνω στο &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt; και
την θέτω ως&amp;nbsp;εξής:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;events {
    worker_connections  1024;
    use epoll;
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Το &lt;code&gt;epoll&lt;/code&gt; σημαίνει &lt;em&gt;efficient method for connection processing&lt;/em&gt; και είναι
ενεργοποιημένο από default στις καινούριες Linux διανομές. Αν έχετε
kernel παλιότερο από &lt;code&gt;Linux 2.6+&lt;/code&gt; τότε ίσως πρέπει να χρησιμοποιήσετε
το απλό &lt;code&gt;poll&lt;/code&gt; ή την &lt;code&gt;standard&lt;/code&gt; μέθοδο η οποία χρησιμοποιείτε σε περίπτώσει
όπου υπάρχει αδυναμία χρήσης της efficient. Τώρα, αν έχετε FreeBSD, Solaris ή ο,τιδήποτε άλλο, περισσότερες πληροφορίες θα βρείτε &lt;a href="http://nginx.org/en/docs/events.html"&gt;εδώ&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id="buffers"&gt;Buffers&lt;/h2&gt;
&lt;p&gt;Αυτό που πρέπει να γνωρίζετε σχετικά με τους buffers, είναι πως αν τους θέσετε
να έχουν πολύ μικρό μέγεθος, τότε ο Nginx θα αναγκαστεί να δημιουργεί τα δικά
του προσωρινά αρχεία. Αυτό σημαίνει ότι θα αρχίσει ένα &amp;#8220;γράψε-διάβασε&amp;#8221;,
το οποίο ανάλογα με τα connections, μπορεί να οδηγήσει σε ανεπιθυμήτο
&lt;em&gt;load&lt;/em&gt; για το σύστημα. Όσο περισσότερο I/O κάνει ένα σύστημα, τόσο περισσότερο
load προκαλεί, τόσο πιο πολύ καθυστερεί να απαντήσει σε &lt;code&gt;requests&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Υπάρχουν 4 buffers για τους οποίους θα μιλήσουμε:
1) Client Buffer Body Size
   Αυτό έχει να κάνει συνήθως με τις &lt;code&gt;post actions&lt;/code&gt;. Όσοι γνωρίζετε &lt;span class="caps"&gt;HTML&lt;/span&gt;
   το μυαλό σας πολύ σωστά έχει πάει σε &lt;code&gt;html forms&lt;/code&gt; ή &lt;code&gt;buttons&lt;/code&gt;.
2) Client Header Buffer Size
   Ακριβώς το ίδιο, αλλά μόνο για τον header. Μία λογική τιμή που προτείνουν
   εδώ οι ειδικοί είναι 1024.
3) Client Max Body Buffer
   Είναι το μέγιστο επιτρεπόμενο μέγεθος για client request. Αν λοιπόν υπερβούμε
   αυτό το όριο, ο Nginx θα πετάξει ένα &lt;a href="https://www.google.de/webhp?sourceid=chrome-instant&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=request%20entity%20too%20large%20413"&gt;413 Error - Request entity too larget&lt;/a&gt;.
4) Large Client Header Buffer
   Το οποίο είναι το ιδιο, αλλά για τον&amp;nbsp;Header.&lt;/p&gt;
&lt;p&gt;Πάμε λοιπόν στο &lt;code&gt;http { }&lt;/code&gt; section και εκεί&amp;nbsp;θέτουμε:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;http {
    ...
    ... 
    client_body_buffer_size 10k;
    client_header_buffer_size 1k;
    client_max_body_size 8m;
    large_client_header_buffers 2 1k;
    ...
    ...
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Εδώ είναι ένα καλό σημείο να κάνουμε save και να τεστάρουμε
αν το configuration έχει κάποιο λάθος (typo ή μη). Τρέχουμε
λοιπόν την εολή &lt;code&gt;nginx -t&lt;/code&gt; και περιμένουμε ένα output σας&amp;nbsp;αυτό:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;configuration&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="sr"&gt;/etc/nginx/&lt;/span&gt;&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;conf&lt;/span&gt; &lt;span class="n"&gt;syntax&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;ok&lt;/span&gt;
&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;configuration&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="sr"&gt;/etc/nginx/&lt;/span&gt;&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;conf&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;successful&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2 id="timeouts"&gt;Timeouts&lt;/h2&gt;
&lt;p&gt;Τα Timetous είναι ένα άλλο σημαντικό ζήτημα που αν δεν το λάβετε σοβαρά 
υπόψην σας, μπορεί να στραγγίξει όλη την δύναμη του πανίσχυρου server σας
και να τον μετατρέψει από μία High Performance μηχανή σ&amp;#8217;ένα αργό πεισματάρικο
γαϊδουράκι. Εδώ&amp;nbsp;έχουμε:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Client Body&amp;nbsp;Timeout&lt;/li&gt;
&lt;li&gt;Client Header&amp;nbsp;Timeout&lt;/li&gt;
&lt;li&gt;Keepalive&amp;nbsp;Timeout&lt;/li&gt;
&lt;li&gt;Send&amp;nbsp;Timeout&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;και τα θέτω ως&amp;nbsp;εξής:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    client_body_timeout 12;
    client_header_timeout 12;
    keepalive_timeout 15;
    send_timeout 10;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Τα παραπάνω, αποτελούν ένα τυπικό configuration για τον Nginx με μέτριο
προς υψηλό&amp;nbsp;traffic.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Socket ονομάζουμε τον συνδυασμό &lt;code&gt;IP&lt;/code&gt; και &lt;code&gt;port&lt;/code&gt;. πχ &lt;code&gt;127.0.0.1:80&lt;/code&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="nginx"></category><category term="server"></category></entry><entry><title>Βασικό configuration του Nginx</title><link href="http://drpaneas.github.io/testblog/vasiko-configuration-tou-nginx" rel="alternate"></link><updated>2015-02-02T21:34:00+02:00</updated><author><name>Πανος Γεωργιαδης</name></author><id>tag:drpaneas.github.io,2015-02-02:testblog/vasiko-configuration-tou-nginx</id><summary type="html">&lt;p&gt;Σε αυτό το άρθρο θα μιλήσουμε για βασικές ρυθμήσεις που πρέπει να κάνουμε
στον Nginx. Οι ρυθμήσεις αυτές έχουν περισσότερο την έννοια του 
optimization, παρά του configuration, καθώς ο Nginx έρχεται &lt;em&gt;pretty much&lt;/em&gt;
configured, οπότε εδώ θα μιλήσουμε τις &lt;strong&gt;βέλτιστες ρυθμήσεις&lt;/strong&gt;. Για να κάνω μία
εισαγωγή, θα μιλήσουμε για πράγματα όπως: &lt;em&gt;πόση μνήμη έχουμε διαθέσιμη&lt;/em&gt;,
&lt;em&gt;πόσους πυρήνες (cpu) θα διαθέσουμε&lt;/em&gt;, και πώς αυτά θα επιδράσουν 
στον συνολικό αριθμό των &lt;em&gt;processes&lt;/em&gt;, &lt;em&gt;threads&lt;/em&gt;, κ.α. πραγμάτων που σχετίζονται
με τους πόρους και την λειτουργία του Nginx &lt;strong&gt;στο σύστημά μας&lt;/strong&gt;. Τονίζω το
&amp;#8220;&lt;em&gt;σύστημά μας&lt;/em&gt;&amp;#8221; γιατί ο σκοπός μου δεν είναι να σας δώσω έτοιμο το 
&lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt; αλλά να σας δείξω ποιες ρυθμήσεις είναι &lt;em&gt;common use&lt;/em&gt;
και ποιες χρειάζονται λίγο &lt;em&gt;tweaking&lt;/em&gt; από την πλευρά&amp;nbsp;σας. &lt;/p&gt;
&lt;p&gt;Πάμε λοιπόν&amp;nbsp;&amp;#8230;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;vim /etc/nginx/nginx.conf
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Το αρχείο με το οποίο θα ασχοληθούμε, είναι το &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;
το οποίο αποτελεί το βασικό αρχείο ρυθμήσεων του Nginx. Είναι το Νο1
αρχείο στο οποίο κοιτάει ο Nginx να βρει πληροφορίες. Μόλις το ανοίξετε,
θα δείτε ένα χάος από επιλογές και μεταβλητές οι οποίες άλλες είναι ήδη
&lt;em&gt;defined&lt;/em&gt; κι άλλες είναι απλά μαρκαρισμένες ως &lt;code&gt;#comment&lt;/code&gt;. Μην σας πιάνει
πανικός, πάμε να τις&amp;nbsp;δούμε:&lt;/p&gt;
&lt;h3&gt;Worker&amp;nbsp;Processes&lt;/h3&gt;
&lt;p&gt;Η μεταβλητή &lt;code&gt;worker_processes&lt;/code&gt; μαζί με την &lt;code&gt;worker_connections&lt;/code&gt; που θα δούμε
στην συνέχεια, αποτελούν στην ουσία το &lt;em&gt;backbone&lt;/em&gt; του Nginx. Ξεκινόντας
με την πρώτη, αυτό που κάνει είναι να λέει στον server (ή τον virtual server)
πόσους workers να διαθέσει για ένα connection. Μόλις ολοκληρωθεί το
&lt;em&gt;πάρε-δώσε&lt;/em&gt; τον μηνυμάτων και οριστικοποιηθούν έννοιες όπως &lt;em&gt;dest &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/em&gt;,
&lt;em&gt;source &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/em&gt;, &lt;em&gt;&lt;span class="caps"&gt;TCP&lt;/span&gt; Port&lt;/em&gt;, &lt;em&gt;&lt;span class="caps"&gt;UDP&lt;/span&gt; Port&lt;/em&gt;, τότε ο Nginx κάνει spawn μία στρατιά
από &lt;em&gt;workers&lt;/em&gt; οι οποίοι είναι υπεύθυνοι για κατάσταση του εκάστωτε &lt;em&gt;connection&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;παράδειγμα&lt;/em&gt;: Όταν συνδέεστε στο &lt;code&gt;localhost:80&lt;/code&gt;, ο Nginx θα ψάξει να δει τι τιμή
έχει η μεταβλητή &lt;code&gt;worker_processes&lt;/code&gt; και ανάλογα θα πράξει. Από default λοιπόν
αυτή η λειτουργία αξιοποιείται στην &lt;code&gt;TCP 80&lt;/code&gt; για &lt;code&gt;http&lt;/code&gt; protocol και στην
&lt;code&gt;TCP 443&lt;/code&gt; για &lt;code&gt;ssl&lt;/code&gt; (μην μπερδεύεστε, το &lt;code&gt;https&lt;/code&gt; εννοώ). Για οποιοδήποτε άλλο
&lt;code&gt;socket&lt;/code&gt;&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt;, θα πρέπει να το ρυθμήσουμε διαφορετικά ή να αγοράσουμε το
εμπορικό μέρος του Nginx. Δεν είμα όμως σίγουρος, οπότε λέω να μην σας μπλέξω
με αυτό. Άλλωστε δεν νομίζω να το χρειάζεστε, εκτός κι αν έχετε κάποιο
αρκετά σύνθετο configuration, όπως για παράδειγμα πολλά &lt;code&gt;ethX&lt;/code&gt; interfaces
ή πολλά &lt;em&gt;&lt;span class="caps"&gt;VM&lt;/span&gt;&lt;/em&gt;s σε &lt;code&gt;bridge mode&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;H formula που χρησιμοποιείται ευρέως στο Internet&amp;nbsp;λέει:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;1 worker για κάθε core&amp;nbsp;processor&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Προφανώς αυτό δεν είναι πανάκεια, δηλαδή μπορεί κάποιος να πει:
&amp;#8220;&lt;em&gt;Και γιατί ρε φίλε να μην βάλω 2 workers για κάθε core; Θα πάθει κάτι;
Θα χαλάσει;&lt;/em&gt;&amp;#8220;. Η απάντηση είναι, χμ, οκ δεν θα πάθει κάτι αλλά είναι
&lt;em&gt;bad practice&lt;/em&gt;, και ως &lt;em&gt;side effect&lt;/em&gt; μπορεί να έχει κάποια connections
να παραμένουν &lt;em&gt;idle&lt;/em&gt; για αρκετό διάστημα, στα οποία όμως να σπαταλούνται
workers, άρα επεξεργαστική ισχύ. Κακή διαχείριση πόρων λοιπόν &amp;#8212; είναι κάτι
που θέλουμε να αποφύγουμε, ειδικά στην περίπτωση μου που έχω έναν μικρό
Atom Processor. Στην δική μου περίπτωση λοιπόν, γνωρίζω ότι έχω έναν
&lt;em&gt;Intel(R) Atom(&lt;span class="caps"&gt;TM&lt;/span&gt;) &lt;span class="caps"&gt;CPU&lt;/span&gt; N2800 @ 1.86GHz&lt;/em&gt;, o οποίος σύμφωνα με τα 
&lt;a href="http://ark.intel.com/products/58917/Intel-Atom-Processor-N2800-1M-Cache-1_86-GHz"&gt;specs&lt;/a&gt; είναι dual core με hyperthreading. Αυτό σημαίνει ότι έχω 4 threads.
Άρα, σύμφωνα με την παραπάνω formula, θα δώσω 1 worker για κάθε thread,&amp;nbsp;συνεπώς:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;worker_processes  4;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Στην δική σας περίπτωση, αν δεν γνωρίζετε τι επεξεργαστή τρέχετε στον server,
ή το &lt;span class="caps"&gt;VPS&lt;/span&gt;, μπορείτε απλά να ρίξετε μια ματιά στο &lt;code&gt;/proc/cpuinfo/&lt;/code&gt;. Για κάποιον
ηλίθιο λόγο, έχουν μπερδέψει την έννοια του &lt;code&gt;processor&lt;/code&gt; με του &lt;code&gt;thread&lt;/code&gt;, οπότε
αρκεί να μετρήσετε πόσα &lt;em&gt;instances&lt;/em&gt; του &lt;code&gt;processor&lt;/code&gt; σας εμφανίζει. Για να μάθετε
να σκέφτεστε με εντολές bash, αυτό προϋποθέτει ένα &lt;code&gt;cat&lt;/code&gt; του αρχείου, στην 
συνέχεια ένα &lt;code&gt;grep&lt;/code&gt; του &lt;em&gt;string&lt;/em&gt; &lt;code&gt;processor&lt;/code&gt; μέσω ενός &lt;code&gt;|&lt;/code&gt;, το οποίο στην περίπτωση μου, θα&amp;nbsp;δώσε:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;ns348481:~ # cat /proc/cpuinfo | grep &amp;quot;processor&amp;quot;
processor   : 0
processor   : 1
processor   : 2
processor   : 3
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Οπότε, είτε μετράω με το μάτι, και βλέπω 4 processors (n+1) γιατί
ξεκινάει από τον &amp;#8220;μηδέν&amp;#8221;, ή απλά ξανά κάνω &lt;code&gt;pipe&lt;/code&gt; και περνάω τα instances
από έναν &lt;em&gt;μετρητή ανα γραμμή&lt;/em&gt;, δηλαδή &lt;code&gt;wc -l&lt;/code&gt;, δηλαδή κάπως&amp;nbsp;έτσι:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat /proc/cpuinfo | grep &amp;quot;processor&amp;quot; | wc -l
4
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Αν κάνω το λάθος, το παίξω &lt;em&gt;άπλας&lt;/em&gt;, και δώσω μεγαλύτερο νούμερο, τότε
για τον δικό μου server σημαίνει ότι δεσμεύω περισσότερους υπολογιστικούς
πόρους από όσους πραγματικά έχω. Τι θα γίνει λοιπόν στην περίπτωση όπου υπάρχει
όντως μεγάλο &lt;em&gt;load&lt;/em&gt; και θα χρειαστούν αυτοί οι παραπάνω πόροι (τους οποίους
δήλωσα εσφαλμένα ότι έχω;) ; Πρόβλημα! Για αυτό λοιπόν, σαν καλός μηχανικός
θα δώσω τον σωστό αριθμό, και θα αφήσω τα &lt;em&gt;μεγάλα λόγια&lt;/em&gt; για τους πολιτικούς.
Computers don&amp;#8217;t&amp;nbsp;lie.&lt;/p&gt;
&lt;h3&gt;Worker&amp;nbsp;Connections&lt;/h3&gt;
&lt;p&gt;Η δεύτερη αλλά εξίσου σημαντική μεταβλητή, είναι η &lt;code&gt;worker_connections&lt;/code&gt;
η οποία βρίσκεται μέσα στο &lt;code&gt;events {}&lt;/code&gt; structure. Το νούμερο που θα βάλουμε εδώ
συμβολίζει το αριθμό των ταυτόχρονων connections. Με άλλα λόγια, είναι το
πόσοι users μπορούν να συνδεθούν ταυτόχρονα, στον server. Αν και αυτό δεν
είναι απολύτως σωστό, καθώς αν και συνήθως στην θεωρία ο browser ανοίγει
ένα connection, στην πράξη αυτο φαίνεται να είναι 3 ή τουλάχιστον παραπάνω
από 1. By default, ο Nginx έχει ορίσει την τιμή στα &lt;code&gt;768&lt;/code&gt; connections, αλλά 
εμείς θα θέσουμε την βέλτιστη τιμή για το σύστημά σας, την οποία θα μας δώσει
η εντολή &lt;code&gt;ulimit&lt;/code&gt;. Αρκετές φορές χρησιμοποιώ αυτή την εντολή, ειδικά όταν
τρέχω κάποιον &lt;em&gt;bug reproducer&lt;/em&gt; όπου γνωρίζω εκ των πρωτέρων ότι θα έρθω
αντιμέτωπος με κάποιο &lt;code&gt;segmentation fault&lt;/code&gt;. Για να μπορέσω να κάνω debugging
με το &lt;code&gt;gdb&lt;/code&gt;, θα πρέπει να ορίσω τον αριρθμό τον maximum resources που μπορώ να
δεσμεύσω στο σύστημα (και εδώ έρχεται η &lt;code&gt;ulimit&lt;/code&gt;). Σε διαφορετική, αν το σύστημα
αρχίζει να τρέχει υπερβολικά πολλές processes ή να καταναλώνει υπερβολική μνήμη
τότε είναι θέμα χρόνου μέχρι να γίνει το όλο πράγμα &lt;em&gt;unresponsive&lt;/em&gt;. 
Για όσους δεν πιστεύουν ότι μπορεί να κρασάρει το Linux, be my guest και 
τρέξτε την ακόλουθη εντολή &lt;code&gt;:(){ :|:&amp;amp; };:&lt;/code&gt; η οποία είναι κλασσικό &lt;code&gt;fork bomb&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Λέγοντας όλα αυτά, είναι εμφανές ότι ο Nginx θέλει να αποφύγει παρόμοια προβλήματα τα οποία θα οφείλονται σε μαζική κίνηση από έναν ή περισσότερους users.
Βάζοντας μια μικρή τιμή, τότε περιορίζουμε την επισκεψημότητά μας, ενώ
βάζοντας υψηλή τιμή υπερεκτιμάμε τις δυνατότητες του μηχανήματός μας. Η πιο
σωστή επιλογή λοιπόν είναι να βάλουμε ακριβώς το &lt;em&gt;sweet spot&lt;/em&gt;, το οποίο θα μας
το δώσει η εκτέλεση της εντολής &lt;code&gt;ulimit -n&lt;/code&gt;. Στην δική μου περίπτωση, το
&lt;em&gt;output&lt;/em&gt; της εντολής είναι &lt;code&gt;1024&lt;/code&gt;, οπότε πάνω στο &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt; και
την θέτω ως&amp;nbsp;εξής:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;events {
    worker_connections  1024;
    use epoll;
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Το &lt;code&gt;epoll&lt;/code&gt; σημαίνει &lt;em&gt;efficient method for connection processing&lt;/em&gt; και είναι
ενεργοποιημένο από default στις καινούριες Linux διανομές. Αν έχετε
kernel παλιότερο από &lt;code&gt;Linux 2.6+&lt;/code&gt; τότε ίσως πρέπει να χρησιμοποιήσετε
το απλό &lt;code&gt;poll&lt;/code&gt; ή την &lt;code&gt;standard&lt;/code&gt; μέθοδο η οποία χρησιμοποιείτε σε περίπτώσει
όπου υπάρχει αδυναμία χρήσης της efficient. Τώρα, αν έχετε FreeBSD, Solaris ή ο,τιδήποτε άλλο, περισσότερες πληροφορίες θα βρείτε &lt;a href="http://nginx.org/en/docs/events.html"&gt;εδώ&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Buffers&lt;/h2&gt;
&lt;p&gt;Αυτό που πρέπει να γνωρίζετε σχετικά με τους buffers, είναι πως αν τους θέσετε
να έχουν πολύ μικρό μέγεθος, τότε ο Nginx θα αναγκαστεί να δημιουργεί τα δικά
του προσωρινά αρχεία. Αυτό σημαίνει ότι θα αρχίσει ένα &amp;#8220;γράψε-διάβασε&amp;#8221;,
το οποίο ανάλογα με τα connections, μπορεί να οδηγήσει σε ανεπιθυμήτο
&lt;em&gt;load&lt;/em&gt; για το σύστημα. Όσο περισσότερο I/O κάνει ένα σύστημα, τόσο περισσότερο
load προκαλεί, τόσο πιο πολύ καθυστερεί να απαντήσει σε &lt;code&gt;requests&lt;/code&gt;. &lt;/p&gt;
&lt;p&gt;Υπάρχουν 4 buffers για τους οποίους θα μιλήσουμε:
1) Client Buffer Body Size
   Αυτό έχει να κάνει συνήθως με τις &lt;code&gt;post actions&lt;/code&gt;. Όσοι γνωρίζετε &lt;span class="caps"&gt;HTML&lt;/span&gt;
   το μυαλό σας πολύ σωστά έχει πάει σε &lt;code&gt;html forms&lt;/code&gt; ή &lt;code&gt;buttons&lt;/code&gt;.
2) Client Header Buffer Size
   Ακριβώς το ίδιο, αλλά μόνο για τον header. Μία λογική τιμή που προτείνουν
   εδώ οι ειδικοί είναι 1024.
3) Client Max Body Buffer
   Είναι το μέγιστο επιτρεπόμενο μέγεθος για client request. Αν λοιπόν υπερβούμε
   αυτό το όριο, ο Nginx θα πετάξει ένα &lt;a href="https://www.google.de/webhp?sourceid=chrome-instant&amp;amp;ion=1&amp;amp;espv=2&amp;amp;ie=UTF-8#q=request%20entity%20too%20large%20413"&gt;413 Error - Request entity too larget&lt;/a&gt;.
4) Large Client Header Buffer
   Το οποίο είναι το ιδιο, αλλά για τον&amp;nbsp;Header.&lt;/p&gt;
&lt;p&gt;Πάμε λοιπόν στο &lt;code&gt;http { }&lt;/code&gt; section και εκεί&amp;nbsp;θέτουμε:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;http {
    ...
    ... 
    client_body_buffer_size 10k;
    client_header_buffer_size 1k;
    client_max_body_size 8m;
    large_client_header_buffers 2 1k;
    ...
    ...
}
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Εδώ είναι ένα καλό σημείο να κάνουμε save και να τεστάρουμε
αν το configuration έχει κάποιο λάθος (typo ή μη). Τρέχουμε
λοιπόν την εολή &lt;code&gt;nginx -t&lt;/code&gt; και περιμένουμε ένα output σας&amp;nbsp;αυτό:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;the&lt;/span&gt; &lt;span class="n"&gt;configuration&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="sr"&gt;/etc/nginx/&lt;/span&gt;&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;conf&lt;/span&gt; &lt;span class="n"&gt;syntax&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;ok&lt;/span&gt;
&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;configuration&lt;/span&gt; &lt;span class="n"&gt;file&lt;/span&gt; &lt;span class="sr"&gt;/etc/nginx/&lt;/span&gt;&lt;span class="n"&gt;nginx&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="na"&gt;conf&lt;/span&gt; &lt;span class="n"&gt;test&lt;/span&gt; &lt;span class="k"&gt;is&lt;/span&gt; &lt;span class="n"&gt;successful&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Timeouts&lt;/h2&gt;
&lt;p&gt;Τα Timetous είναι ένα άλλο σημαντικό ζήτημα που αν δεν το λάβετε σοβαρά 
υπόψην σας, μπορεί να στραγγίξει όλη την δύναμη του πανίσχυρου server σας
και να τον μετατρέψει από μία High Performance μηχανή σ&amp;#8217;ένα αργό πεισματάρικο
γαϊδουράκι. Εδώ&amp;nbsp;έχουμε:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Client Body&amp;nbsp;Timeout&lt;/li&gt;
&lt;li&gt;Client Header&amp;nbsp;Timeout&lt;/li&gt;
&lt;li&gt;Keepalive&amp;nbsp;Timeout&lt;/li&gt;
&lt;li&gt;Send&amp;nbsp;Timeout&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;και τα θέτω ως&amp;nbsp;εξής:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;    client_body_timeout 12;
    client_header_timeout 12;
    keepalive_timeout 15;
    send_timeout 10;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Τα παραπάνω, αποτελούν ένα τυπικό configuration για τον Nginx με μέτριο
προς υψηλό&amp;nbsp;traffic.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Socket ονομάζουμε τον συνδυασμό &lt;code&gt;IP&lt;/code&gt; και &lt;code&gt;port&lt;/code&gt;. πχ &lt;code&gt;127.0.0.1:80&lt;/code&gt;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="nginx"></category><category term="server"></category></entry><entry><title>Εγκατάσταση του Nginx</title><link href="http://drpaneas.github.io/testblog/egkatastasi-tou-nginx" rel="alternate"></link><updated>2015-01-29T23:58:00+02:00</updated><author><name>Πανος Γεωργιαδης</name></author><id>tag:drpaneas.github.io,2015-01-29:testblog/egkatastasi-tou-nginx</id><summary type="html">&lt;p&gt;Μετά την εισαγωγή στο προηγούμενο άρθρο, ήρθε η στιγμή να ξεκινήσουμε τις
νέες μας περιπέτειες με τον Nginx. Για να γίνει όμως αυτό, όπως συμβαίνει
γενικά με κάθε πρόγραμμα, πρέπει πρώτα από όλα, να εγκατασήσουμε 
και να ρυθμήσουμε τον Nginx στο σύστημά μας. &lt;em&gt;Truth be told&lt;/em&gt;, σε αυτό τό
άρθρο θα αναφερθώ περισσότερο στο πώς να τον κάνετε εγκατάσταση, παρά
στο πώς να τον&amp;nbsp;ρυθμίσετε.&lt;/p&gt;
&lt;p&gt;Για όσους βαριούνται να διαβάζουν, έχω ετοιμάσει ένα μικρό βιντεάκι
&lt;a href="http://youtu.be/9EWDZJ0c6Ug?hd=1"&gt;Εγκατάσταση&amp;nbsp;nginx&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;Στην συνέχεια του άρθρου θα βρείτε πληροφορίες για κάθε &lt;em&gt;βασική&lt;/em&gt;&amp;nbsp;διανομή.&lt;/p&gt;
&lt;h4&gt;Centos 7 / Red Hat&amp;nbsp;7&lt;/h4&gt;
&lt;p&gt;Για όσους χρησιμοποιούν CentOS, θα χρειαστούν το αντίστοιχο
repository της &lt;em&gt;epel&lt;/em&gt;. Με ένα γρήγορο google search θα μάθετε (όσοι δεν
γνωρίζετε ήδη), ότι το epel (ή μάλλον &lt;span class="caps"&gt;EPEL&lt;/span&gt; με κεφαλαία), σημαίνει:
&lt;strong&gt;E&lt;/strong&gt;xtra &lt;strong&gt;P&lt;/strong&gt;ackages for &lt;strong&gt;E&lt;/strong&gt;nterprise &lt;strong&gt;L&lt;/strong&gt;inux και μπορείτε να μάθετε τα 
πάντα για αυτό το &lt;em&gt;project&lt;/em&gt; στο σχετικό &lt;a href="https://fedoraproject.org/wiki/EPEL"&gt;wiki του fedora project&lt;/a&gt;. Για όσους χρησιμοποιούν λοιπόν, είτε Centos 7
είτε &lt;span class="caps"&gt;RHEL&lt;/span&gt; 7, το repo προστείθετε στο σύστημά σας, υπό την μορφή ενός &lt;span class="caps"&gt;RPM&lt;/span&gt;.
Το κατεβάζετε, το εγκαθιστάτε και &lt;em&gt;voila&lt;/em&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;wget http://dl.fedoraproject.org/pub/epel/7/x86_64/e/epel-release-7-5.noarch.rpm
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Μην με ρωτήσει κανείς &lt;em&gt;πού είναι το link για 32-bit arch&lt;/em&gt;, γιατί
πολύ απλά το Centos 7, δεν βγαίνει για 32-bit processors. Τόσο απλά :)
Επίσης, αν δεν έχετε το wget, εγκαταστήστε το &lt;code&gt;yum install wget&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Αν &lt;strong&gt;δεν είστε σίγουροι&lt;/strong&gt; σχετικά με το ποια ακριβώς έκδοση CentOS
ή &lt;span class="caps"&gt;RHEL&lt;/span&gt; έχετε εγκατεστημένη, τότε μπορείτε να το μάθετε με την&amp;nbsp;εντολή:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;cat /etc/os-release 
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Αφού έχουμε κάνει &lt;em&gt;fetch&lt;/em&gt; το rpm, δεν μένει παρά να το&amp;nbsp;εγκαταστήσουμε:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;rpm -Uvh epel-release-7-5.noarch.rpm
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Πάμε να κάνουμε ένα &lt;em&gt;verify&lt;/em&gt; ότι &lt;em&gt;epel&lt;/em&gt; repo προστέθηκε με&amp;nbsp;επιτυχία:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;yum repolist | grep epel
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Ας κάνουμε τώρα ένα &lt;em&gt;pull&lt;/em&gt; της cache database της repolist 
ώστε να ανανεωθούν τα αρχεία. Συγκεκριμένα με ενδιαφέρει
το &lt;code&gt;/etc/yum.repos.d/epel.repo&lt;/code&gt; αλλά τα ανανεώνω όλα γιατί
είναι πιο εύκολο και δεν διαρκεί πολύ. Μετά από αυτό, το λογικό
είναι να έχουμε πλέον το nginx έτοιμο προς εγκατάστηση στα&amp;nbsp;repos.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;yum update
yum install nginx
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Κατά την εγκατάσταση θα δείτε ότι έχει αρκετές dependecies, αρκετές
από αυτές είναι ίδιες με αυτές του Apache. Ωστόσο, έχετε και κάποιες
μοναδικές για αυτόν, όπως η λειτουργία GeoIP και το ίδιο το&amp;nbsp;nginx-filesystem.&lt;/p&gt;
&lt;h4&gt;Debian 7, Ubuntu 14 &lt;span class="caps"&gt;LTS&lt;/span&gt;&lt;/h4&gt;
&lt;p&gt;Εδώ τα πράγματα είναι πολύ απλά. Δεν χρειάζεται κανένα 
επιπλέον&amp;nbsp;repo.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;sudo apt-get install nginx
&lt;/pre&gt;&lt;/div&gt;


&lt;h4&gt;OpenSUSE&lt;/h4&gt;
&lt;p&gt;Κι εδώ τα πράγματα εξακολουθούν να είναι&amp;nbsp;πανεύκολα:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;zypper in nginx
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;Ενεργοποιήση του&amp;nbsp;service&lt;/h3&gt;
&lt;p&gt;Αφού ολοκληρωθεί η εγκατάσταση, αυτό που έχουμε να κάνουμε
είναι να βάλουμε τον &lt;em&gt;daemon&lt;/em&gt; να ξεκινάει κατά το &lt;em&gt;startup&lt;/em&gt;. Το οποίο
για όσους γνωρίζουν το &lt;em&gt;systemd&lt;/em&gt; αυτό σημαίνει ότι θα χρειαστούν την
εντολή &lt;code&gt;systemctl enable nginx.service&lt;/code&gt;, ενώ οι παλιοί μπορούν να
χρησιμοποιήσουν &lt;code&gt;chkconfig nginx on&lt;/code&gt;. Έτσι λοιπόν, σε οποιοδήποτε
runlevel κι αν bootάρει το σύστημά σας (εκτός από το recovery προφανώς),
θα εκκινήσει μαζί του και ο nginx. Έχοντας πλέον ρυθμίσει την εκκίνηση
κατά το boot, ήρθε η στιγμή να τον βάλουμε μπρος και να ελέξουμε
ότι όλα πήγαν καλά. Για να ξεκινήσουμε τον nginx δίνουμε, είτε
&lt;code&gt;systemctl start nginx.service&lt;/code&gt; για όσους έχουν &lt;em&gt;systemd&lt;/em&gt;, είτε
&lt;code&gt;service start nginx&lt;/code&gt; για τους&amp;nbsp;υπόλοιπους.&lt;/p&gt;
&lt;h3&gt;Έλεγχος του&amp;nbsp;webserver&lt;/h3&gt;
&lt;p&gt;Ξανά, έχω ετοιμάσει ένα &lt;a href="https://www.youtube.com/watch?v=4ICaaNUVOsE"&gt;2o βιντεάκι&lt;/a&gt;
για όσους προτιμάνε το Youtube από την ανάγνωση (και καλά&amp;nbsp;κάνουν).&lt;/p&gt;
&lt;p&gt;Για ελέξουμε ότι ο webserver λειτουργεί κανονικά, θα εγκαταστήσουμε
έναν μικρό ελαφρύ και console-based browser (ή μάλλον ncurses-based),
 με τον οποίον θα ανοίξουμε το &lt;code&gt;index.html&lt;/code&gt; στο &lt;code&gt;localhost&lt;/code&gt;. Για αυτόν τον σκοπό
θα χρησιμοποιήσουμε τον &lt;code&gt;lynx&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;yum install lynx
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Αφού τον εγκαταστήσουμε, δοκιμάζουμε να επισκεφτούμε, το localhost, περιμένοντας
να δούμε την &lt;em&gt;default&lt;/em&gt; &lt;code&gt;localhost&lt;/code&gt; webpage του nginx: &lt;code&gt;lynx http://localhost&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Ελπίζω όλα να πήγαν καλά! Στα παρακάτω άρθρα θα αναφερθούμε σε ρυθμήσεις γύρω
από τον nginx. Για να πάρετε μία ιδέα, το &lt;em&gt;directory&lt;/em&gt; που θα δουλεύουμε
είναι το &lt;code&gt;/etc/nginx&lt;/code&gt;. Εκεί η δομή δεν διαφέρει από αυτά που θα έχετε πιθανώς
δει στον &lt;em&gt;apache&lt;/em&gt;.Παρόλα αυτά, το πιο σημαντικό
αρχείο που έχει να κάνει με την ρύθμιση του server αυτού, καθ&amp;#8217;αυτού,
με την έννοια του daemon/service, είναι το &lt;code&gt;/etc/nginx/nginx.conf&lt;/code&gt;. Σε
αυτό το αρχείο θέτουμε πού θα μπουν τα logs (από default
πηγαίνουν στο &lt;code&gt;/var/log/nginx.log&lt;/code&gt;), πού θα βρίσκεται το &lt;span class="caps"&gt;PID&lt;/span&gt; αρχείο,
πόσους πυρήνες και threads θα δεσμεύσουμε&amp;nbsp;κλπ.&lt;/p&gt;
&lt;p&gt;Τα αρχεία, προς το παρών, φαίνεται ότι τοποθετούνται στο &lt;code&gt;/srv/www/htdocs/&lt;/code&gt;
directory.&lt;/p&gt;
&lt;p&gt;Οπότε, λέγοντας αυτά, πιστεύω ότι πήρατε μία &lt;em&gt;γεύση&lt;/em&gt;
σχετικά με το τι θα ασχοληθούμε στα υπόλοιπα άρθρα&amp;nbsp;:)&lt;/p&gt;</summary><category term="nginx"></category><category term="server"></category></entry><entry><title>Εισαγωγή στον Nginx</title><link href="http://drpaneas.github.io/testblog/eisagogi-ston-nginx" rel="alternate"></link><updated>2015-01-22T23:19:00+02:00</updated><author><name>Πανος Γεωργιαδης</name></author><id>tag:drpaneas.github.io,2015-01-22:testblog/eisagogi-ston-nginx</id><summary type="html">&lt;p&gt;Σε αυτό το άρθρο θα μιλήσουμε για τον Nginx&lt;sup id="fnref:1"&gt;&lt;a class="footnote-ref" href="#fn:1" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; &lt;span class="caps"&gt;HTTP&lt;/span&gt; Webserver (ω ναι, υπάρχουν κι άλλοι webservers πέρα από τον &lt;em&gt;Apache&lt;/em&gt;). Όταν λέω ότι θα κάνουμε μία εισαγωγή, εννοώ ότι θα ξεκινήσουμε την εξερεύνηση απαντώντας σε κάποια από τα βασικά ερωτήματα,&amp;nbsp;όπως:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Σε τι διαφέρει από τον&amp;nbsp;Apache;&lt;/li&gt;
&lt;li&gt;Ποια είναι να χαρακτηριστικά&amp;nbsp;του;&lt;/li&gt;
&lt;li&gt;Γιατί να ασχοληθούμε μαζί&amp;nbsp;του;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Καταρχάς, ο Nginx δεν είναι καινούριος. Υπάρχει εδώ και αρκετό καιρό στην &lt;em&gt;πιάτσα&lt;/em&gt;, συγκεκριμένα το dev ξεκίνησε το 2002 και το 2004 κυκλοφόρισε η πρώτη του έκδοση. Ωστόσο το τελευταίο διάστημα
βλέπω ότι έχει αρχίζει να τραβάει πάνω του αρκετή προσοχή. Μάλιστα, &lt;strong&gt;δεν είναι λίγοι&lt;/strong&gt; εκείνοι που έκαναν την μετάβαση από τον &amp;#8220;Βασιλιά Των Webservers&amp;#8221; (&lt;em&gt;βλ.&lt;/em&gt; Apache) στον Nginx. Παρόλα αυτά, ο Apache εξακολουθεί να κρατάει σταθερά τα ηνία του &lt;span class="caps"&gt;HTTP&lt;/span&gt;, αφού κατέχει περίπου το 50-75% των webservers του Internet. Το ερώτημα, λοιπόν,&amp;nbsp;είναι:&lt;/p&gt;
&lt;h2&gt;Γιατί να ασχοληθεί κανείς με τον&amp;nbsp;Nginx&lt;/h2&gt;
&lt;p&gt;Σαν κλασσικός σπασίκλας, θα σας κάνω &lt;em&gt;quote&lt;/em&gt; από την&amp;nbsp;Wikipedia:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Nginx is an open source reverse proxy server for &lt;span class="caps"&gt;HTTP&lt;/span&gt;, &lt;span class="caps"&gt;HTTPS&lt;/span&gt;, &lt;span class="caps"&gt;SMTP&lt;/span&gt;, &lt;span class="caps"&gt;POP3&lt;/span&gt;, and &lt;span class="caps"&gt;IMAP&lt;/span&gt; protocols, as well as a load balancer, &lt;span class="caps"&gt;HTTP&lt;/span&gt; cache, and a web&amp;nbsp;server.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Ωραία και; Γιατί να μην βάλω&amp;nbsp;Apache;&lt;/h3&gt;
&lt;p&gt;Η πιο λογική ερώτηση είναι γιατί να μην ασχοληθεί κανείς με τον Apache; Μία σκέψη που θα μπορούσε να πει κάποιος είναι: &amp;#8220;Εδώ το μισό Internet σερβίρει&amp;#8230; &lt;em&gt;σε εμένα θα &amp;#8220;κολλήσει&amp;#8221;;&lt;/em&gt; &amp;#8221;
Καταρχάς μην πάσχετε από &lt;em&gt;Argumentum ad populum&lt;/em&gt;&lt;sup id="fnref:2"&gt;&lt;a class="footnote-ref" href="#fn:2" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt;. Κατά δεύτερον, η διαφορά του Nginx με τον Apache, είναι ότι ο Nginx &lt;strong&gt;κάνει τα ίδια πράγματα, αλλά με τα &amp;#8220;διαφορετικό τρόπο&amp;#8221;&lt;/strong&gt;. Τώρα θα μου πείτε, τι εννοείς λέγοντας &amp;#8220;&lt;em&gt;διαφορετικό&lt;/em&gt;&amp;#8220;; Είναι &amp;#8220;&lt;em&gt;καλύτερος&lt;/em&gt;&amp;#8220;; Είναι &amp;#8220;&lt;em&gt;χειρότερος&lt;/em&gt;&amp;#8220;;&lt;/p&gt;
&lt;p&gt;Well, in this context I mean&amp;nbsp;&amp;#8230; &lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;διαφορετικός τρόπος = πολλές φορές καλύτερος από τον&amp;nbsp;Apache&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Για να το πω πιο τεχνικά, ο &lt;strong&gt;Nginx διαφέρει από τον Apache στον τρόπο που χειρίζεται τα requests&lt;/strong&gt;. Ας αρχίζουμε όμως με τον Apache, ο οποίος μεταχειρίζεται (by default) τα &lt;em&gt;requests&lt;/em&gt; όπως και η κάρτα γραφικών, δηλαδή: παράλληλα και σε &lt;code&gt;threads&lt;/code&gt;. Το μοντέλο αυτό θα το ακούσετε και αλλιώς ως &lt;code&gt;process-oriented&lt;/code&gt;. Με απλά λόγια, σημαίνει ότι: για 1 connection κάνει generate τουλάχιστον 1 thread, και φυσικά ο σκοπός είναι να τα επεξεργάζεται (όλα αυτά τα) threads παραλληλα. Πολύ έξυπνο! Πάντα ήμουν &lt;em&gt;fan&lt;/em&gt; του parallel thread processing, αλλά πριν βιαστείτε δώσετε ±1, πρέπει πρώτα να σκεφτείτε ποια είναι τα πλεονεκτήματα και τα μειονεκτήματα αυτού του&amp;nbsp;μοντέλου. &lt;/p&gt;
&lt;p&gt;Ένα από τα &lt;strong&gt;μειονεκτήματα&lt;/strong&gt; είναι το γεγονός ότι αν έχουμε μπόλικο static content, δηλ. πολλά αρχεία,
τότε αρχίζει και καταλαμβάνει περισσότερη μνήμη από το κανονικό, και αυτό το φαινόμενο συνεχίζει να επιδεινώνεται μέχρι να τερματίσει το εκάστωτε&amp;nbsp;session.&lt;/p&gt;
&lt;p&gt;Από την άλλη μεριά, ο Nginx δεν λειτουργεί με αυτόν τον τρόπο. Χρησιμοποιεί έναν &lt;code&gt;asynchronous event-handler&lt;/code&gt; και με αυτόν
διαχειρίζεται τα requests. Αυτό σημαίνει ότι, ακόμα κι αν μεταχειρίζεται τις εισερχόμενες connections ως ανεξάρτητες μεταξύ τους, 
τις επιτρέπει να &lt;strong&gt;μοιράζονται&lt;/strong&gt;, να κάνουν share, το memory space. Αυτό το γεγονός επιτρέπει στον Nginx να αποδίδει πολύ καλά
κάτω υπό συνθήκες μεγάλου φόρτου. Και στην πραγματικότητα, αυτός είναι ο πιο σημαντικός λόγος για τον οποίον αρκετοί
προτιμούν τον Nginx έναντι του Apache. Με τον Apache webserver, μπορείτε να &lt;em&gt;σερβίρετε&lt;/em&gt; &lt;strong&gt;ταυτόχρονα/παράλληλα&lt;/strong&gt; μερικές
εκατοντάδες connections, οι οποίες όμως εξαρτώνται &amp;#8220;αρκετά&amp;#8221; από τα hardware resources, και συγκεκριμένο τον χώρο και την μνήμη
που διαθέτει το μηχάνημα. Ειδικά τώρα που τα περισσότερα websites φορτώνουν διάφορα &lt;span class="caps"&gt;CMS&lt;/span&gt;, όπως Wordpress ή Drupal, το καθένα
από αυτά είναι αρκετά βαρύ και μπορεί να γίνει ακόμα πιο βαρύ προσθέτοντας διάφορα plugin. Συνεπώς, μην σας παραξενεύει
ότι το &lt;span class="caps"&gt;VPS&lt;/span&gt; των 5 Ευρώ που νοικιάζετε, με 128mb &lt;span class="caps"&gt;RAM&lt;/span&gt;, Apache και Wordpress, αρχίζει να &lt;em&gt;σέρνεται&lt;/em&gt; σε ώρες &lt;strong&gt;αιχμής&lt;/strong&gt;. Σε αντίθεση,
ο Nginx μπορεί να ανταπεξέλθει εξυπηρετώντας (όχι εκατοντάδες, αλλά) χιλιάδες connections με μικρότερη ή τουλάχιστον ίδια μνήμη,
χωρίς να έχει πρόβλημα με τις&amp;nbsp;sessions.&lt;/p&gt;
&lt;h2&gt;Nginx&amp;nbsp;Features&lt;/h2&gt;
&lt;p&gt;Ο Nginx έχει ένα κάρο χαρακτηριστικά, αλλά θα σταθούμε στα πιο σημαντικά, ενώ θα τα συγκρίνουμε και με τα αντίστοιχα του&amp;nbsp;Apache.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Διαχειρίζεται static files, index files, και κάνει auto indexing&lt;/strong&gt;: Το ίδιο και ο Apache, πάμε&amp;nbsp;παρακάτω&amp;#8230;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Reverse proxy with caching&lt;/strong&gt;: Το ίδιο μπορεί να γίνει και στον Apache, αλλά απαιτεί επιπλέον&amp;nbsp;modules&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Load balancing&lt;/strong&gt;: Το ίδιο κάνει και ο Apache, αλλά θέλει plugin, ενώ ο Nginx το κάνει έχει built-in&amp;nbsp;;)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Support fault tolerance&lt;/strong&gt;: Σας επιτρέπει να κάνετε configure πολλούς nodes που θα μοιρίζονται το ίδιο session state στην μνήμη μεταξύ τους. Δεν υπάρχει κάτι αντίστοιχο για τον&amp;nbsp;Apache.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;OpenSSL Support (including &lt;span class="caps"&gt;SNI&lt;/span&gt; και &lt;span class="caps"&gt;OCSP&lt;/span&gt; stapling)&lt;/strong&gt;: Αυτό είναι σημαντικό γιατί όπως είδατε πρόσφατα&lt;sup id="fnref:3"&gt;&lt;a class="footnote-ref" href="#fn:3" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt;, το &lt;em&gt;&lt;span class="caps"&gt;SSL&lt;/span&gt;&lt;/em&gt; είναι πλέον το πιο &lt;em&gt;trendy&lt;/em&gt; στόχαστρο των hackers. Οπότε, υποστηρίζοντας τα &lt;em&gt;latest and greatest&lt;/em&gt; της κρυπτογραφίας, &lt;em&gt;ίσως&lt;/em&gt; είναι&amp;nbsp;καλύτερο.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;FastCGI, &lt;span class="caps"&gt;PHP&lt;/span&gt;-&lt;span class="caps"&gt;FPM&lt;/span&gt; και &lt;span class="caps"&gt;SCGI&lt;/span&gt; Support&lt;/strong&gt;: Στην ουσία είναι modules που προσδίδουν την δυνατότητα εκτέλεσης scripts (&lt;em&gt;πχ&lt;/em&gt; php), τα οποία μπορεί να κάνουν ο,τιδήποτε μας έρθει στο κεφάλι, αλλά αυτά που συναντάμε συνήθως έχουν να κάνουν με τα κλασσικά πράγματα που απασχολούν τον &lt;em&gt;web development&lt;/em&gt;, όπως πχ το &lt;em&gt;authetication&lt;/em&gt;.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Fully IPv6&lt;/strong&gt;: Υποστηρίζει πλήρως το IPv6. Το ίδιο και ο Apache αλλά με module, μετά την έκδοση&amp;nbsp;2.2&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Websockets και &lt;span class="caps"&gt;HTTP&lt;/span&gt;/1.1&lt;/strong&gt;: Αναμενόμενο και για τους δύο, αφού είναι&amp;nbsp;webserver.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Live stream file compression&lt;/strong&gt;: Ιδανικό για video streaming. Ο Apache δεν διαθέτει κάτι&amp;nbsp;ανάλογο.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;&lt;span class="caps"&gt;URL&lt;/span&gt; Redirects και rewriting&lt;/strong&gt;: Ψωμοτύρι για τους webservers, πάμε&amp;nbsp;παρακάτω&amp;#8230;&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Bandwidth Throttling&lt;/strong&gt;: Υποστηρίζεται και στον Apache μέσω modules, ενώ στον nginx είναι απλά μία ρύθμιση το base configuration&amp;nbsp;file.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Geolocation of &lt;span class="caps"&gt;IP&lt;/span&gt;&lt;/strong&gt;: Από τις πιο &lt;em&gt;sexy&lt;/em&gt; τεχνολογίες του Nginx, όπου σου παρέχει έναν τρόπο να κάνεις διαχείριση των &lt;span class="caps"&gt;IP&lt;/span&gt; σε σχέση με την τοποθεσία τους. Χρησιμοποιείται κυρίως για CDNs&lt;sup id="fnref:4"&gt;&lt;a class="footnote-ref" href="#fn:4" rel="footnote"&gt;4&lt;/a&gt;&lt;/sup&gt; που &lt;em&gt;σερβίρουν&lt;/em&gt; static&amp;nbsp;content.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;ΠΟΛΥ Λίγη μνήμη&lt;/strong&gt;: Όπως είπαμε και πριν, μπορεί να διαχειριστεί &lt;strong&gt;10.000 ταυτόχρονες συνδέσεις με μόλις 2.5mb μνήμης&lt;/strong&gt; χωρίς πρόβλημα στο keep-alive πάρα-δώσε που έχουν οι sessions για να παραμένουν&amp;nbsp;ανοιχτές.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Είναι η νέα γενιά των&amp;nbsp;webservers&lt;/h2&gt;
&lt;p&gt;Όπως ξέρουμε τα πράγματα σήμερα, ο Apache είναι ο Βασιλιάς των Webserbers, σερβίροντας το Internet
στα πιάτα των περισσότερων ανθρώπων. Ωστόσο, όσο το Internet of Things αρχίζει να μπαίνει όλο και
περισσότερο στην ζωή μας, η ανάγκη για &lt;em&gt;better perfomance&lt;/em&gt; γίνεται όλο και πιο επιτακτική. Σκεφτείτε
πόσες συσκευές χρησιμοποιούμε στην καθημεριμενότητά μας, και πόσες από αυτές χρησιμοποιούν δίκτυο: &lt;span class="caps"&gt;TV&lt;/span&gt;, Smart-Watch, Smartphones, Keyboards, Tablets κλπ είναι λογικό λοιπόν, αφού αυξάνονται οι clients
να αυξάνονται και τα connections προς τους servers. Σκεπτόμενοι ότι ο &lt;em&gt;average Joe&lt;/em&gt; θέλει να 
έχει άμεση πρόσβαση στο περιεχόμενό του, είναι ανυπόμονος και θέλει να του σερβίρουν (server) το φαγητό (web) &amp;#8220;&lt;em&gt;τώρα&lt;/em&gt;&amp;#8220;, τότε τουλάχιστον 2 πράγματα είναι ξεκάθαρα ότι θα&amp;nbsp;χρειαστούμε:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Μείωση του Response&amp;nbsp;Time&lt;/li&gt;
&lt;li&gt;Περισσότερες παράλληλες&amp;nbsp;συνδέσεις&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Για την ώρα λοιπόν, όσο η ανάγκη για το Internet of Things μεγαλώνει, τόσο μεγαλύτερη
διαφήμιση θα αποκτά ο&amp;nbsp;Nginx.&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:1"&gt;
&lt;p&gt;Προφέρεται &amp;#8220;engine&amp;#8221; &amp;#8220;X&amp;#8221;&amp;#160;&lt;a class="footnote-backref" href="#fnref:1" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:2"&gt;
&lt;p&gt;Σύνδρομο της Αγγέλης (&lt;a href="http://el.wikipedia.org/wiki/%CE%A3%CF%8D%CE%BD%CE%B4%CF%81%CE%BF%CE%BC%CE%BF_%CF%84%CE%B7%CF%82_%CE%B1%CE%B3%CE%AD%CE%BB%CE%B7%CF%82"&gt;περισσότερα&lt;/a&gt;)&amp;#160;&lt;a class="footnote-backref" href="#fnref:2" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:3"&gt;
&lt;p&gt;Αναφέρομαι στο Heartbleed bug&amp;#160;&lt;a class="footnote-backref" href="#fnref:3" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:4"&gt;
&lt;p&gt;&lt;span class="caps"&gt;CDN&lt;/span&gt; είναι μία ομάδα από webnodes, που σου σερβίρουν περιεχόμενο με βάση το που βρίσκεσαι (την γεωγραφική σου τοποθεσία). Δηλαδή επιλέγουν να σου στείλουν το content από τον server που βρίσκεται πιο κοντά
σου.&amp;#160;&lt;a class="footnote-backref" href="#fnref:4" rev="footnote" title="Jump back to footnote 4 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</summary><category term="nginx"></category><category term="server"></category></entry></feed>